{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import GPUtil\n",
    "from collections import defaultdict\n",
    "from analysis import utils as au\n",
    "from analysis import plotting\n",
    "from data import utils as du\n",
    "from data import se3_diffuser\n",
    "from data import r3_diffuser\n",
    "from data import so3_diffuser\n",
    "import seaborn as sns\n",
    "from model import loss\n",
    "from model import reverse_se3_diffusion\n",
    "import tree\n",
    "from data import rosetta_data_loader\n",
    "from data import digs_data_loader\n",
    "from data import all_atom\n",
    "from experiments import train_se3_diffusion\n",
    "from experiments import inference_se3_diffusion\n",
    "from openfold.utils import rigid_utils as ru\n",
    "from openfold.np import residue_constants\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import importlib\n",
    "\n",
    "# Enable logging\n",
    "import logging\n",
    "import sys\n",
    "date_strftime_format = \"%Y-%m-%y %H:%M:%S\"\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(asctime)s %(message)s\", datefmt=date_strftime_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'experiments.train_se3_diffusion' from '/data/rsg/chemistry/jyim/projects/protein_diffusion/experiments/train_se3_diffusion.py'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rosetta_data_loader)\n",
    "importlib.reload(digs_data_loader)\n",
    "importlib.reload(se3_diffuser)\n",
    "importlib.reload(so3_diffuser)\n",
    "importlib.reload(r3_diffuser)\n",
    "importlib.reload(du)\n",
    "importlib.reload(au)\n",
    "importlib.reload(all_atom)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(loss)\n",
    "importlib.reload(reverse_se3_diffusion)\n",
    "importlib.reload(inference_se3_diffusion)\n",
    "importlib.reload(train_se3_diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading checkpoint from ../pkl_jar/ckpt/with_aatype_0/11D_09M_2022Y_11h_44m_55s/step_470000.pth\n",
      "INFO: Saving results to ../results/11D_09M_2022Y_11h_44m_55s\n",
      "INFO: Number of model parameters 3703648\n",
      "INFO: Using cached IGSO3.\n",
      "INFO: Checkpoints saved to: ./pkl_jar/ckpt/with_aatype_0/11D_09M_2022Y_11h_44m_55s/with_aatype_0/13D_09M_2022Y_21h_57m_10s\n",
      "INFO: Evaluation saved to: ./results/with_aatype_0/11D_09M_2022Y_11h_44m_55s/with_aatype_0/13D_09M_2022Y_21h_57m_10s\n",
      "INFO: Training: 1000 examples\n",
      "INFO: Validation: 40 examples with lengths [ 60  90 113 134 156 177 198 218 239 260]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "inference_conf_path = '../config/inference.yaml'\n",
    "inference_conf = OmegaConf.load(inference_conf_path)\n",
    "# inference_conf.ckpt_dir = '../pkl_jar/ckpt/exp_lin_with_aatype_0/11D_09M_2022Y_13h_12m_28s'\n",
    "inference_conf.ckpt_dir = '../pkl_jar/ckpt/with_aatype_0/11D_09M_2022Y_11h_44m_55s'\n",
    "# inference_conf.ckpt_dir = '../pkl_jar/ckpt/baseline_0/11D_09M_2022Y_13h_06m_45s'\n",
    "inference_conf.default_conf_path = '../config/base.yaml'\n",
    "inference_conf.output_dir = '../results'\n",
    "\n",
    "# print(OmegaConf.to_yaml(inference_conf))\n",
    "\n",
    "# Set up sampler\n",
    "sampler = inference_se3_diffusion.Sampler(inference_conf)\n",
    "train_loader, valid_loader = sampler.exp.create_rosetta_dataset(0, 1)\n",
    "train_csv = train_loader.dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Training: 1000 examples\n",
      "INFO: Validation: 40 examples with lengths [ 60  90 113 134 156 177 198 218 239 260]\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader = sampler.exp.create_rosetta_dataset(0, 1)\n",
    "train_csv = train_loader.dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample using data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample an example\n",
    "\n",
    "# data_iter = iter(train_loader)\n",
    "# next_item = next(data_iter)\n",
    "\n",
    "data_iter = iter(valid_loader)\n",
    "next_item, _ = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Saved sample to ./samples/len_90_1.pdb\n",
      "INFO: Saved trajectory to ./samples/len_90_traj_1.pdb\n",
      "INFO: Saved sample to ./samples/len_177_1.pdb\n",
      "INFO: Saved trajectory to ./samples/len_177_traj_1.pdb\n",
      "INFO: Saved sample to ./samples/len_217_1.pdb\n",
      "INFO: Saved trajectory to ./samples/len_217_traj_1.pdb\n",
      "INFO: Saved sample to ./samples/len_134_1.pdb\n",
      "INFO: Saved trajectory to ./samples/len_134_traj_1.pdb\n"
     ]
    }
   ],
   "source": [
    "# Run sampler\n",
    "save = True\n",
    "batch_size = 4\n",
    "res_mask = next_item['res_mask'][:batch_size]\n",
    "aatype = next_item['aatype'][:batch_size]\n",
    "res_idx = next_item['res_idx'][:batch_size]\n",
    "samples_traj = sampler.sample(\n",
    "    res_mask=res_mask,\n",
    "    aatype=aatype,\n",
    "    save=save,\n",
    "    res_idx=res_idx,\n",
    "    file_prefix='./samples/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PDB.PDBParser(QUIET=True)\n",
    "\n",
    "pdb_path = './samples/len_90_1.pdb'\n",
    "pdb_name = 'test'\n",
    "structure = parser.get_structure(pdb_name, pdb_path)\n",
    "\n",
    "struct_chains = {\n",
    "    chain.id: chain\n",
    "    for chain in structure.get_chains() if chain.id == 'A'}\n",
    "# TODO: Add logic for handling multiple chains.\n",
    "assert len(struct_chains) == 1\n",
    "\n",
    "# chain_prot = process_chain(struct_chains['A'], 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metrics = metrics.protein_metrics(saved_path, unpad_prot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sample without data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Saved sample to ./samples/len_150_1.pdb\n",
      "INFO: Saved trajectory to ./samples/len_150_traj_1.pdb\n",
      "INFO: Saved sample to ./samples/len_150_2.pdb\n",
      "INFO: Saved trajectory to ./samples/len_150_traj_2.pdb\n",
      "INFO: Saved sample to ./samples/len_150_3.pdb\n",
      "INFO: Saved trajectory to ./samples/len_150_traj_3.pdb\n",
      "INFO: Saved sample to ./samples/len_150_4.pdb\n",
      "INFO: Saved trajectory to ./samples/len_150_traj_4.pdb\n"
     ]
    }
   ],
   "source": [
    "# Run sampler\n",
    "batch_size = 4\n",
    "num_res = 150\n",
    "res_mask = torch.ones((batch_size, num_res))\n",
    "save = True\n",
    "samples_traj = sampler.sample(\n",
    "    res_mask=res_mask,\n",
    "    save=save,\n",
    "    file_prefix='./samples/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
