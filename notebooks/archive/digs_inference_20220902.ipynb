{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import GPUtil\n",
    "from collections import defaultdict\n",
    "from analysis import utils as au\n",
    "from analysis import plotting\n",
    "from data import utils as du\n",
    "from data import se3_diffuser\n",
    "from data import r3_diffuser\n",
    "from data import so3_diffuser\n",
    "from model import loss\n",
    "from model import reverse_se3_diffusion\n",
    "import tree\n",
    "from data import rosetta_data_loader\n",
    "from data import digs_data_loader\n",
    "from experiments import train_se3_diffusion\n",
    "from openfold.utils import rigid_utils as ru\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import importlib\n",
    "\n",
    "# Enable logging\n",
    "import logging\n",
    "import sys\n",
    "date_strftime_format = \"%Y-%m-%y %H:%M:%S\"\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(asctime)s %(message)s\", datefmt=date_strftime_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rosetta_data_loader)\n",
    "importlib.reload(digs_data_loader)\n",
    "importlib.reload(se3_diffuser)\n",
    "importlib.reload(so3_diffuser)\n",
    "importlib.reload(r3_diffuser)\n",
    "importlib.reload(du)\n",
    "importlib.reload(loss)\n",
    "importlib.reload(reverse_se3_diffusion)\n",
    "importlib.reload(train_se3_diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_conf_path = '../config/inference.yaml'\n",
    "inference_conf = OmegaConf.load(inference_conf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_conf.ckpt_dir = '../pkl_jar/ckpt/subset_1000_31D_08M_2022Y_14h_59m_25s'\n",
    "inference_conf.default_conf_path = '../config/base.yaml'\n",
    "inference_conf.output_dir = '../results'\n",
    "\n",
    "print(OmegaConf.to_yaml(inference_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "\n",
    "    def __init__(self, conf: DictConfig):\n",
    "        self._log = logging.getLogger(__name__)\n",
    "        self._infer_conf = conf\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        self._load_ckpt()\n",
    "\n",
    "    def _load_ckpt(self):\n",
    "        ckpt_dir = self._infer_conf.ckpt_dir\n",
    "        if len(os.listdir(ckpt_dir)) != 1:\n",
    "            raise ValueError(f'Ambiguous ckpt in {ckpt_dir}')\n",
    "        ckpt_name = os.listdir(ckpt_dir)[0]\n",
    "        self._output_dir = os.path.join(self._infer_conf.output_dir, os.path.basename(ckpt_dir))\n",
    "        os.makedirs(self._output_dir, exist_ok=True)\n",
    "        ckpt_path = os.path.join(ckpt_dir, ckpt_name)\n",
    "        self._log.info(f'Loading checkpoint from {ckpt_path}')\n",
    "        self._log.info(f'Saving results to {self._output_dir}')\n",
    "\n",
    "        # Read checkpoint and create experiment.\n",
    "        ckpt_pkl = du.read_pkl(ckpt_path)\n",
    "        ckpt_conf = ckpt_pkl['conf']\n",
    "        ckpt_model = ckpt_pkl['model']\n",
    "        default_conf = OmegaConf.load(self._infer_conf.default_conf_path)\n",
    "        self._exp_conf = OmegaConf.merge(default_conf, ckpt_conf)\n",
    "        self._exp_conf.experiment.data_location = 'digs'\n",
    "        self._exp_conf.data.digs.cache_dir = 'pkl_jar/'\n",
    "        \n",
    "        self.exp = train_se3_diffusion.Experiment(conf=self._exp_conf)\n",
    "        self.exp._model = self.exp._model.to(self.device)  \n",
    "        self.exp.model.load_state_dict(ckpt_model)\n",
    "        \n",
    "        self.diffuser = self.exp.diffuser\n",
    "        \n",
    "        self.scale_factor = self.exp._data_conf.scale_factor\n",
    "    \n",
    "    def sample(self, batch_size, num_res, file_prefix=None):\n",
    "        \n",
    "        # Initialize data\n",
    "        rigids_init = self.diffuser.sample_ref(\n",
    "            num_res * batch_size \n",
    "        ).to_tensor_7().reshape((batch_size, num_res, 7))\n",
    "        init_feats = {\n",
    "            'rigids_t': rigids_init,\n",
    "            'res_mask': torch.ones((batch_size, num_res)),\n",
    "            'res_idx': torch.tile(\n",
    "                torch.arange(1, num_res+1)[None], (batch_size, 1)),\n",
    "        }\n",
    "        init_feats = tree.map_structure(\n",
    "            lambda x: x.to(self.device), init_feats)\n",
    "        \n",
    "        # Run inference\n",
    "        infer_out = sampler.exp.inference_fn(\n",
    "            init_feats, add_noise=True)\n",
    "        sampled_rigids = infer_out[0]\n",
    "        final_samples = sampled_rigids[-1]\n",
    "        traj_samples = torch.stack(sampled_rigids).transpose(0, 1)\n",
    "        \n",
    "        # Save each sample\n",
    "        pdb_name = f'len_{num_res}_sample.pdb'\n",
    "        traj_name = f'len_{num_res}_trajectory.pdb'\n",
    "        if file_prefix is not None:\n",
    "            pdb_name = f'{file_prefix}_' + pdb_name\n",
    "            traj_name = f'{file_prefix}_' + traj_name\n",
    "        for i in range(batch_size):\n",
    "            self.save_ca_pdb(final_samples[i][..., 4:], pdb_name)\n",
    "            self.save_ca_pdb(traj_samples[i][..., 4:], traj_name)\n",
    "        return sampled_rigids\n",
    "        \n",
    "    def save_ca_pdb(self, ca_pos, pdb_name, rescale=True):\n",
    "        if rescale:\n",
    "            ca_pos = ca_pos * self.scale_factor\n",
    "        save_path = os.path.join(self._output_dir, pdb_name)\n",
    "        return au.write_prot_to_pdb(\n",
    "            du.move_to_np(ca_pos),\n",
    "            save_path\n",
    "        )\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler(inference_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_res = 120\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_outputs = sampler.sample(batch_size, num_res, file_prefix='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_samples = sampled_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_i = final_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigids_init = sampler.diffuser.sample_ref(\n",
    "    num_res * batch_size \n",
    ").to_tensor_7().reshape((batch_size, num_res, 7))\n",
    "init_feats = {\n",
    "    'rigids_t': rigids_init,\n",
    "    'res_mask': torch.ones((batch_size, num_res)),\n",
    "    'res_idx': torch.tile(\n",
    "        torch.arange(1, num_res+1)[None], (batch_size, 1)),\n",
    "}\n",
    "init_feats = tree.map_structure(lambda x: x.to(sampler.device), init_feats)\n",
    "infer_out = sampler.exp.inference_fn(\n",
    "    init_feats, add_noise=True)\n",
    "sampled_rigids = infer_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 120, 7])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_rigids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final design as PDB.\n",
    "ca_pos = final_rigid[:, 4:] * scale_factor\n",
    "num_res = du.move_to_np(torch.sum(res_mask))\n",
    "file_path = f'../samples/pdb/{os.path.basename(ckpt_dir)}/len_{num_res}_sample.pdb'\n",
    "file_dir = os.path.dirname(file_path)\n",
    "os.makedirs(file_dir, exist_ok=True)\n",
    "\n",
    "save_path = au.write_prot_to_pdb(\n",
    "    du.move_to_np(ca_pos),\n",
    "    file_path\n",
    ")\n",
    "print(f'Written to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pkl_jar/ckpt/subset_1000_31D_08M_2022Y_14h_59m_25s/epoch_51.pkl\n"
     ]
    }
   ],
   "source": [
    "base_conf_path = '../config/base.yaml'\n",
    "base_conf = OmegaConf.load(base_conf_path)\n",
    "\n",
    "# Load model checkpoint\n",
    "# ckpt_dir = '../pkl_jar/ckpt/subset_1000_exp_lin_31D_08M_2022Y_15h_49m_56s'\n",
    "# ckpt_dir = '../pkl_jar/ckpt/subset_1000_lin_lin_31D_08M_2022Y_15h_00m_54s'\n",
    "# ckpt_dir = '../pkl_jar/ckpt/subset_100_01D_09M_2022Y_02h_47m_59s'\n",
    "# ckpt_dir = '../pkl_jar/ckpt/baseline_01D_09M_2022Y_05h_20m_34s'\n",
    "ckpt_dir = '../pkl_jar/ckpt/subset_1000_31D_08M_2022Y_14h_59m_25s'\n",
    "# ckpt_dir = '../pkl_jar/ckpt/subset_1000_lin_log_4_01D_09M_2022Y_02h_47m_59s'\n",
    "# ckpt_dir = '../pkl_jar/ckpt/baseline_01D_09M_2022Y_10h_45m_05s'\n",
    "# ckpt_dir = '../pkl_jar/ckpt/pdb_lin_log_3_01D_09M_2022Y_11h_25m_32s'\n",
    "\n",
    "\n",
    "if len(os.listdir(ckpt_dir)) != 1:\n",
    "    raise ValueError(f'Ambiguous ckpt in {ckpt_dir}')\n",
    "ckpt_path = os.path.join(\n",
    "    ckpt_dir, os.listdir(ckpt_dir)[0])\n",
    "print(ckpt_path)\n",
    "ckpt_pkl = du.read_pkl(ckpt_path)\n",
    "ckpt_conf = ckpt_pkl['conf']\n",
    "ckpt_model = ckpt_pkl['model']\n",
    "\n",
    "\n",
    "conf = OmegaConf.merge(base_conf, ckpt_conf)\n",
    "conf.experiment.data_location = 'digs'\n",
    "conf.data.digs.cache_dir = '../pkl_jar/'\n",
    "\n",
    "# print(OmegaConf.to_yaml(ckpt_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Number of model parameters 3488030\n",
      "INFO: Using cached IGSO3.\n",
      "INFO: Loaded data at ../pkl_jar/dataset_5.0_260_60_80.0_100_2020-Apr-30_1000.pkl\n",
      "INFO: Loaded data at ../pkl_jar/dataset_5.0_260_60_80.0_100_2020-Apr-30_1000.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = train_se3_diffusion.Experiment(conf=conf)\n",
    "train_loader, train_sampler, valid_loader, valid_sampler = exp.create_digs_dataset(0, 1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "exp._model = exp._model.to(device)\n",
    "exp.model.load_state_dict(ckpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data point to initializez.\n",
    "data_iter = iter(train_loader)\n",
    "raw_data_feats = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample length 206\n"
     ]
    }
   ],
   "source": [
    "# Preprocess init data\n",
    "exp_diffuser = exp.diffuser\n",
    "# batch_idx = 2\n",
    "# data_feats = tree.map_structure(lambda x: x[batch_idx], raw_data_feats)\n",
    "data_feats = traw_data_feats\n",
    "res_mask = data_feats['res_mask']\n",
    "res_idx = data_feats['res_idx']\n",
    "rigids_0 = data_feats['rigids_0']\n",
    "\n",
    "# rigids_0 = rigids_0[torch.where(res_mask.bool())]\n",
    "# res_mask = res_mask[torch.where(res_mask.bool())]\n",
    "\n",
    "num_res = res_mask.shape[0]\n",
    "rigids_init = exp_diffuser.sample_ref(\n",
    "    num_res,\n",
    "    impute=ru.Rigid.from_tensor_7(rigids_0)\n",
    ").to_tensor_7()\n",
    "rigids_init *= res_mask[:, None]\n",
    "init_feats = {\n",
    "    'rigids_t': rigids_init,\n",
    "    'res_mask': res_mask,\n",
    "    'res_idx': res_idx,\n",
    "#     'res_idx': res_idx[torch.where(res_mask.bool())],\n",
    "    't': torch.tensor(1.0),\n",
    "    'rot_score_norm': data_feats['rot_score_norm'],\n",
    "    'trans_score_norm': data_feats['trans_score_norm'],\n",
    "}\n",
    "\n",
    "num_res = res_mask.shape[0]\n",
    "init_feats = tree.map_structure(lambda x: x[None].to(device), init_feats)\n",
    "print(f'Sample length {torch.sum(res_mask)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "infer_out = exp.inference_fn(init_feats, add_noise=True)\n",
    "sample_rigids = infer_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out SE(3)\n",
    "final_rigid = sample_rigids[-1][0]\n",
    "f, axes = plt.subplots(1, 3, figsize=[24, 8], subplot_kw=dict(projection=\"3d\"))\n",
    "scale_factor = conf.data.digs.scale_factor\n",
    "ax_lim = 15.\n",
    "plotting.viz_frames(init_feats['rigids_t'][0], res_mask, axes[0], title='Initialization', scale_factor=scale_factor, ax_lim=ax_lim)\n",
    "plotting.viz_frames(final_rigid, res_mask, axes[1], title='Sample', scale_factor=scale_factor, ax_lim=ax_lim)\n",
    "plotting.viz_frames(rigids_0, res_mask, axes[2], title='Ground truth', scale_factor=scale_factor, ax_lim=ax_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FAPE and Ca-RMSD metrics.\n",
    "fape_loss = loss.rigids_fape(\n",
    "    final_rigid,\n",
    "    rigids_0.to(device),\n",
    "    res_mask.to(device),\n",
    "    length_scale=scale_factor)\n",
    "rmsd_loss, aligned_pred_ca, gt_ca, align_rot_mat, align_trans, reflection = loss.rigids_ca_rmsd(\n",
    "    final_rigid,\n",
    "    rigids_0.to(device),\n",
    "    res_mask.to(device),\n",
    "    length_scale=scale_factor,\n",
    "    return_align=True)\n",
    "align_rot_euler = Rotation.from_matrix(align_rot_mat).as_euler('xyz', degrees=True)\n",
    "print(f'FAPE: {fape_loss:2.4f}\\nCa-RMSD: {rmsd_loss:2.4f}')\n",
    "print(f'Alignment rotation: {align_rot_euler}\\nAlignment translation: {align_trans[:,0]}\\nAlignment reflection: {reflection}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize aligned Ca structures\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "plotting.plt_3d(aligned_pred_ca, ax, color='r', s=100, mode='scatter')\n",
    "plotting.plt_3d(aligned_pred_ca, ax, color='r', mode='line')\n",
    "plotting.plt_3d(gt_ca, ax, color='b', s=100, mode='scatter')\n",
    "plotting.plt_3d(gt_ca, ax, color='b', mode='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final design as PDB.\n",
    "ca_pos = final_rigid[:, 4:] * scale_factor\n",
    "num_res = du.move_to_np(torch.sum(res_mask))\n",
    "file_path = f'../samples/pdb/{os.path.basename(ckpt_dir)}/len_{num_res}_sample.pdb'\n",
    "file_dir = os.path.dirname(file_path)\n",
    "os.makedirs(file_dir, exist_ok=True)\n",
    "\n",
    "save_path = au.write_prot_to_pdb(\n",
    "    du.move_to_np(ca_pos),\n",
    "    file_path\n",
    ")\n",
    "print(f'Written to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trajectory as a gif\n",
    "save_path = 'dev_diffusion_linear.gif'\n",
    "sample_traj = torch.stack(sample_rigids)[:, 0]\n",
    "ax_lim = 15\n",
    "plotting.write_traj(\n",
    "    sample_traj, res_mask, save_path, ax_lim=ax_lim, scale_factor=scale_factor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
